"""
RNN Text Generation Project
I will demonstrate how to generate text using a character based RNN. I will work with a dataset of Shakespeares writing.
Given a sequence if characters from this data (Shakespear), train a model to predict the next character in the sequence
(e). Longer sequences of text generated by calling the model repeatedly.

Setup
Import tensorflow and other libraries
"""

import tensorflow as tf
import keras.utils
import keras.layers
import numpy as np
import time
import os
import warnings
warnings.filterwarnings("ignore")


"""
Download Dataset
"""
path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')

# read in, then decode for py2 compat
text = open(path_to_file, 'rb').read().decode(encoding='utf-8')
# length of text is the number of characters in it
print("---------------------------------------------------------")
print(f'length in text: {len(text)} characters')

# print out first 250 characters in text
print("---------------------------------------------------------")
print(text[:250])

# get the unique characters in the file
vocab = sorted(set(text))
print("---------------------------------------------------------")
print(f'{len(vocab)} unique characters')

"""
Process The Text
Vectorize the text
Before training, I need to convert the strings to a numerical representation

The tf.keras.layers.StringLookup layer can convert each character into a numeric ID. Just to split up the text into 
tokens first.
"""

example_texts = ['abcdef', 'xyz']
chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')
print("---------------------------------------------------------")
print(chars)

"""
Now create the tk.keras.layers.StringLookup layer:
"""

ids_from_chars = tf.keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None)

# it converts from tokens to character IDs
ids = ids_from_chars(chars)
print("---------------------------------------------------------")
print(ids)

"""
Since the goal of this project is to generate text, it will also be important to invert this representation and recover 
human-readable strings from it. For this you can use tf.keras.layers.StringLookup(...invert=True)
"""

chars_from_ids = tf.keras.layers.StringLookup(vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)

"""
This layer recovers the characters from the vectors of IDs, and returns them as a tf.RaggedTensor of characters
"""

chars = chars_from_ids(ids)
print("---------------------------------------------------------")
print(chars)

"""
You can tf.strings.reduce_join to join the characters back to strings
"""

# tf.strings.reduce_join(chars, axis=1).numpy()


def text_from_ids(ids):
    return tf.strings.reduce_join(chars_from_ids(ids), axis=1)


"""
The Prediction Task 
Given a character, or a sequence of characters, what is the most probable next character? This is the task you're 
training the model to perform. The input to the model will be a sequence of characters, and you train the model to 
predict the output - the following character at each time step

Since RNNs maintain an internal state that depends on the previously seen elements, given all the characters computed 
until this moment, what is the next character?

Create training examples and targets 
Next divide the text into example sequences. Each input sequence will contain seq_length characters from the text

For each input sequence, the corresponding targets contain the same length of text, except shifted one character to the
right.

So break the text into chunks of seq_length+1. For example, say seq_length is 4 and our text is "Hello". The input 
sequence would be "Hell", and the target sequence "ello".

To do this first use the tf.data.Dataset.from_tensor_slices function to convert the text vector into a stream of 
character indices
"""



